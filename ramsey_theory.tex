\documentclass{article}

% preamble
\def\npart{III}
\def\nyear{2023}
\def\nterm{Michaelmas}
\def\nlecturer{Dr Julian Sahasrabudhe}
\def\ncourse{Ramsey Theory on Graphs}
\def\draft{Incomplete}

\usepackage{mathrsfs}
\usepackage{imakeidx}
\usepackage{marginnote}
\usepackage{mathdots}
\usepackage{tabularx}
\usepackage{ifthen}

\input{header}
\swapnumbers
\reversemarginpar

\usetikzlibrary{positioning, decorations.pathmorphing, decorations.text, calc, backgrounds, fadings}
\tikzset{node/.style = {circle,draw,inner sep=0.8mm}}

\makeindex[intoc]

\setcounter{section}{-1}

% and here we go!
\begin{document}
\maketitle

\tableofcontents

\clearpage
\section{Introduction}

\newlec

\begin{notation}
  We write
  \begin{itemize}
    \item $[n] = \{1, \dots, n\}$
    \item $K_n$ for the complete graph on $n$ vertices.
    \item For $X$ a set, $r \in \N$, $X^{(r)} = \{S \subseteq X | |S| = r\}$
    \item $\chi$ for a $k$-coloring of the edges of $K_n$
      \begin{align*}
        & \chi : E(K_n) \mor [k] & \\
        & \chi : E(K_n) \mor \{\text{red}, \text{blue}\} & (\text{if } k = 2)
      \end{align*}
  \end{itemize}
\end{notation}

Ramsey theory is usually concerned with the following question:

\begin{quotation}
  \textit{Can we find some order in enough disorder?}
\end{quotation}

In this course, we will specialise this question to graphs. We are thus interested in the following:

\begin{quotation}
  \textit{What can we say about the structure of an arbitrary $2$-coloring of the edges of $K_n$?}
\end{quotation}

\begin{defi}
  Define the {\bf Ramsey number} $R(\ell, k)$ to be the least $n$ for which every $2$-edge coloring contains either a blue $K_\ell$ or a red $K_k$, and the {\bf diagonal Ramsey number} $R(k) = R(k, k)$ to be the least $n$ for which every $2$-edge coloring contains a monochromatic $K_k$.
\end{defi}

It is unclear that such a $n$ even exists! We shall prove it in due course.

$R(\ell, k) = R(k, \ell)$. By convention, we will usually assume $\ell \le k$.

\begin{eg}
  $R(3) = 6$ because
  \begin{itemize}
    \item The following coloring shows that $R(3) > 5$. TODO: add picture
    \item If we have $6$ vertices, we can pick a vertex $v$. By pigeonhole, three of the neighbors of $v$ are connected to $v$ via the same color, say red. Now either two of those neighbors are connected with a red edge, in which case they form a red triangle with $v$, or they are connected with blue edges to each other, in which case they form a blue triangle. As a way to remember this proof, we encourage you to watch the following music video: \href{https://youtu.be/vE7MW2lk55E}{Everybody's looking for Ramsey}
  \end{itemize}
\end{eg}

\section{Old bounds on \texorpdfstring{$R(k)$}{R(k)}}

\begin{thm}[Erd\H os-Szekeres, 1935]
  $$R(\ell, k) \le \binom{k + \ell - 2}{\ell - 1}$$
  In particular, $R(\ell, k)$ is well-defined.
\end{thm}

\begin{lemma}
  For all $k, \ell \ge 3$,
  $$R(\ell, k) \le \underbrace{R(\ell - 1, k)}a + \underbrace{R(\ell, k - 1)}b$$
\end{lemma}
\begin{proof}
  Let $n = a + b$. Pick a vertex $v$. By pigeonhole, either
  \begin{itemize}
    \item $v$ has at least $a$ red neighbors. Either these neighbors contain a red $K_{\ell - 1}$ (in which case we chuck $v$ in), or contain a blue $K_k$ (in which case we already won).
    \item $v$ has at least $b$ blue neighbors. Either these neighbors contain a blue $K_{k - 1}$ (in which case we chuck $v$ in), or contain a red $K_\ell$ (in which case we already won).
  \end{itemize}
\end{proof}

\begin{proof}[Proof of Erd\H os-Szekeres]
  Use that $R(\ell, 2) = \ell$ and induct on $k$ and $\ell$.
\end{proof}

\begin{cor}
  $$R(k) \le \binom{2k} k \le C\frac{4^k}{\sqrt k}$$
  for some constant $C$.
\end{cor}

\subsection{Lower bounds}

Can we find edge colorings on many vertices without a monochromatic $K_k$?
Certainly, we can at least do so on $(k - 1)^2$ vertices.

TODO: Insert figure

This polynomial lower bound is eons away from our exponential upper bound. For quite some time (in the 1930s), people thought that the lower bound was closer to the truth than the upper bound. Surprisingly, it is possible to show an exponential lower bound without actually exhibiting such a coloring!

\begin{thm}[Erd\H os, 1948]
  $$R(k) \ge \frac{k - 1}{e\sqrt 2}2^{\frac k 2}$$
\end{thm}
\begin{fact}
  $$\left(\frac n k\right)^k \le \binom n k \le \left(\frac{en}k\right)^k$$
\end{fact}
\begin{proof}
  Let $n = \ceil{\frac{k - 1}{e\sqrt 2}2^{\frac k 2}}$ and $\chi$ be a random red/blue edge coloring of $K_n$ (each edge is independently colored red or blue with probability $\frac 1 2$). We see that
  \begin{eqnarray*}
    \P(\chi \text{ contains a monochromatic } K_k)
    & = & \P\left(\bigcup_{S \in [n]^{(k)}} \{S \text{ monochromatic}\}\right) \\
    & \le & \binom n k \P([k] \text{ monochromatic}) \\
    & = & \binom n k 2^{-\binom k 2 + 1} \\
    & \le & 2 \left(\frac{en}k\right)^k 2^{-\frac{k(k - 1)}2} \\
    & = & 2 \left(\frac{en}k 2^{-\frac{k - 1}2}\right)^k \\
    & \le & 2\left(1 - \frac 1 k\right)^k \\
    & < & 1
  \end{eqnarray*}
  Hence
  $$2^{\frac k 2} \le R(k) \le 4^k$$
\end{proof}

This proof is remarkable by the fact that it proves that the probability of some object existing is high, without actually constructing such an object. In fact it is still an important open problem to explicitly construct a $K_k$-free edge-coloring of $K_n$ with $n$ exponential in $k$. In other words, {\it even though $K_k$-free edge-colorings are abundant, we don't know how to write down a single one}.

\begin{rmk}
  The use of ``constructive'' here is quite different to that in other areas of mathematics. We do not mean that the proof requires the Law of Excluded Middle or the Axiom of Choice, nor that we do not provide an algorithm to find a graph without monochromatic $K_k$. \\
  Since there are only finitely many red/blue edge-colorings of $K_n$ for a fixed $n$, there trivially is an algorithm to find such a coloring: enumerate them all and try them one by one. Less obviously, there is a procedure to systematically remove any use of the axiom of choice from the proofs of most of the results in this course. Excluded Middle is also redundant since the case splits we consider can be decided in finite time (again, everything is finite). \\
  A more careful definition of ``constructive'' here is about complexity of the description of the object: Erd\H os' lower bound does not provide any better {\it deterministic} algorithm than "Try all edge-colorings", and this has complexity $\Omega\left(2^{\binom n 2}\right)$ (without even accounting for the time it takes to check whether a coloring contains a monochromatic $K_k$). In contrast, we would expect a constructive lower bound to yield an edge-coloring in a polynomial number of operations in $n$.
\end{rmk}

\begin{question}
  What's the base of the exponent here? Is there even such a base?
\end{question}

\newlec

We know
$$R(3, k) \le \binom{k + 1}2 \le (k + 1)^2$$

\begin{defi}
  An {\bf independent set} in a graph is a set of vertices that does not contain an edge. The {\bf independence number} $\alpha(G)$ is the maximum size of an independent set of $G$.
\end{defi}

\begin{defi}[Binomial Random Graph]
  For $n \in \N, 0 \le p \le 1$, we define $G(n, p)$ the probability space of graphs where each edge is independently present with probability $p$.
\end{defi}

\begin{thm}[Erd\H os]
  $$R(3, k) \ge c\left(\frac k{\log k}\right)^{\frac 32}$$
  for some constant $c > 0$.
\end{thm}
\begin{proof}
  Change the language. Discuss the blue graph. We are now looking for the maximum number of edges of a graph with no triangles and no independent set of size $k$. \\
  Take $n = \left(\frac k{\log k}\right)^{\frac 32}, p = n^{-\frac 23} = \frac{\log k}k$. Now sample $G \sim G(n, p)$ and define $\tilde G$ to be $G$ with one vertex removed from each triangle and independent set of size $k$. By construction, $K_3 \not\subseteq \tilde G$ and $\alpha(\tilde G) < k$. We will show $\E[\abs{\tilde G}] \ge \frac n2$ using
  $$\abs{\tilde G} \ge n - \#\text{triangles in } G - \#\text{independent sets of size $k$ in } G$$
  First,
  \begin{eqnarray*}
    \E[\#\text{triangles in } G]
    & = & \sum_{T \in [n]^(3)} \P(T \text { triangle in } G) \\
    & = & \binom n3 p^3 \le \frac{(np)^3}6 = \frac n6
  \end{eqnarray*}
  Second,
  \begin{eqnarray*}
    \E[\#\text{independent sets of size $k$ in } G]
    & = & \binom nk (1 - p)^{\binom k2} \\
    & \le & \left(\frac{en}k\right)^k e^{-p\binom k2} \\
    & \sim & \left(\frac{en}k e^{-\frac{pk}2}\right)^k \\
    & = & \left(\frac{ek^{\frac 32}}{k\log^{\frac 32} k} e^{-\frac{\log k}2}\right)^k \\
    & = & \left(\frac e{\log^{\frac 32} k}\right)^k \longrightarrow 0
  \end{eqnarray*}
  Hence, for large enough $k$,
  $$\E[\abs{\tilde G}] \ge n - \frac n6 - 1 \ge \frac n2 = \frac 12 \left(\frac k{\log k}\right)^{\frac 32}$$
  By adjusting $c > 0$, we have proved the theorem.
\end{proof}

We are being wasteful here. Why throw an entire vertex away when we could get away with removing a single edge? Because we might accidentally create an independent set of size $k$. But we can be smarter...

\begin{idea}
  Take a maximal collection of edge-disjoint triangles in $G \sim G(n, p)$ and remove all edges from these triangles.
\end{idea}

\begin{thm}[Erd\H os]
  $$R(3, k) \ge c\left(\frac k{\log k}\right)^2$$
  for some constant $c > 0$.
\end{thm}

\begin{lemma}
  Let $\mathcal F = \{A_1, \dots, A_m\}$ be a family of events in a probability space. Let $\Eps_t$ be the even that $t$ {\it independent} events from $\mathcal F$ occur. then
  $$\P(\Eps_t) \le \frac 1{t!}\left(\sum_{i = 1}^m \P(A_i)\right)^t$$
\end{lemma}
\begin{proof}
  Note that
  $$1_{\Eps_t} \le \frac 1{t!} \sum_{\substack{i \in [m]^t \\ A_{i_1}, \dots, A_{i_t}\text{ independent}}} 1_{A_{i_1}} \dots 1_{A_{i_t}}$$
  So
  \begin{eqnarray*}
    \P(\Eps_t)
    & \le & \frac 1{t!} \sum_{\substack{i \in [m]^t \\ A_{i_1}, \dots, A_{i_t}\text{ independent}}} \P(A_{i_1}) \dots \P(A_{i_t}) \\
    & \le & \frac 1{t!} \sum_{i \in [m]^t} \P(A_{i_1}) \dots \P(A_{i_t}) \\
    & = & \frac 1{t!} \left(\sum_{i = 1}^m \P(A_i)\right)^t
  \end{eqnarray*}
\end{proof}

\newlec

\begin{lemma}
  Let $n, k \in \N, p \in [0, 1]$ be such that $pk \ge 16\log n$. Then with high probability every subset of size $k$ of $G \sim G(n, p)$ contains at least $\frac{pk^2}8$ edges.
\end{lemma}

\begin{proof}[Proof of Erd\H os' bound]
  We fix $n = \left(\frac{c_1 k}{\log k}\right)^2, p = c_2n^{-\frac 12} = \frac{c_2}{c_1}\frac{\log k}k$. Let $G \sim G(n, p), \mathcal T$ a maximal collection of edge-disjoint triangles in $G$, $\tilde G$ be $G$ with all edges of $\mathcal T$ removed. Note, $\tilde G$ contains no triangle. We show
  $$\P(\alpha(\tilde G) \ge k) < 1$$
  Let $Q$ be the event that every set of $k$ vertices of $G$ contains $\ge \frac{pk^2}8$ edges. Setting $\frac{c_2}{c_1} = 48$, we get
  $$pk = \frac{c_2}{c_1}\frac{\log k}k k = 48\log k > 16\log n$$ By the lemma, we know so that $\P(Q) = 1 - o(1)$ by the lemma. Now note that
  $$\P(\alpha(\tilde G) \ge k) \le \P(\alpha(\tilde G) \ge k, Q) + \cancelto 0{\P(Q^c)}$$
  So we focus on $\P(\alpha(\tilde G) \ge k, Q)$. Set $t = \frac{pk^2}{24}$.
  \begin{eqnarray*}
    \P(\alpha(\tilde G) \ge k, Q)
    & \le & \P\left(\exists S \in [n]^{(k)}, \mathcal T \text{ meets $S$ in } \ge \frac{pk^2}8\right) \\
    & \le & \binom n k \P\left(\underbrace{\substack{\text{at least $t$ triangles of $\mathcal T$} \\ \text{meet $[k]$ in at least two vertices}}}_B\right)
  \end{eqnarray*}
  Let $\{T_i\}$ be the collection of triangles in $K_n$ that meet $[k]$ in at least two vertices. Let $A_i = \{T_i \subseteq G\}$. Note that if $T_{i_1}, \dots, T_{i_k}$ are edge-disjoint, then $A_{i_1}, \dots, A_{i_k}$ are independent. So
  \begin{eqnarray*}
    \P(B)
    & \le & \P(\Eps_t) \\
    & \le & \frac 1{t!}\left(\sum_{\substack{T_i \subseteq K_n \text{ intersects } [k] \\ \text{ in at least two vertices}}} \P(T_i \subseteq G)\right)^t \\
    & \le & \frac 1{t!} (k^2np^3)^t \\
    & \le \left(\frac{ek^2np^3}t\right)^t \\
    & = & (24enp^2)^t = (24ec_2^2)^t = e^{-t}
  \end{eqnarray*}
  by choosing $c_2 = \frac 1{\sqrt{24} e}$. To finish, observe that
  $$t = \frac{pk^2}{24} = 2k\log k \ge k\log n$$
  Hence
  $$\binom n k \P(B) \le \binom n k e^{-t} \le \left(\frac{en}k e^{-\log n}\right)^k = \left(\frac ek\right)^k \mor 0$$
\end{proof}


\section{Large deviation inequalities}

Let $Z$ be a gaussian random variable.
$$\P(Z - \E[Z] \ge t) \le e^{\frac{-t}{2\Var Z}}$$
Let $X_1, \dots, X_n$ be iid Bernoulli random variables. We denote this $X_i \sim \Ber(p)$. Write $S_n = X_1 + \dots + X_n$. Note $\E[S_n] = np$, $\Var(S_n)=np(1 - p)$.

\begin{idea}
  Often, the tail of $S_n$ looks like a gaussian tail.
\end{idea}

\begin{thm}[Chernoff inequality]
  Let $X_1, \dots, X_n \sim \Ber(p)$. Then
  $$\P\left(\abs{S_n - pn} \ge t\right) \le 2\exp\left(\underbrace{-\frac t{2pn}}_{\text{meat}} + \underbrace{\frac{t^3}{(pn)^2}}_{\text{error term}}\right)$$
\end{thm}

\newlec

\printindex
\end{document}